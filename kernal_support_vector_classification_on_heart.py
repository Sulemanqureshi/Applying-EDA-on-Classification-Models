# -*- coding: utf-8 -*-
"""Kernal Support Vector Classification on heart.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YKVqa9K3hoWO_dw7e7roDvnULxu-QrTV

#Kernal Support Vector Classification

##Import Libraries
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

"""#Load the Dataset"""

df = pd.read_csv('heart.csv')

"""# Split the data into features (X) and target (y)"""

X = df.drop('target', axis=1)
y = df['target']

"""#Train-Test Split"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""# Feature Scaling

"""

from sklearn.preprocessing import StandardScaler

# Feature Scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""# Initialize the Kernel SVM model with different kernels

"""

kernels = ['linear', 'poly', 'rbf', 'sigmoid']

""" # Initialize the SVM model with the specified kernel

"""

for kernel in kernels:  # Iterate over the kernels
    svm_model = SVC(kernel=kernel, probability=True, random_state=42)
    svm_model = SVC(kernel=kernel, probability=True, random_state=42)

"""# Retrain the SVM model with scaled data

"""

# Create an instance of the SVM model
svm_model.fit(X_train_scaled, y_train)

"""#EDA

# 1. Initial Data Exploration
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.model_selection import train_test_split


# Create DataFrames for better visualization
df_train = pd.DataFrame(X_train, columns=[
    'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg',
    'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal'
])
df_test = pd.DataFrame(X_test, columns=df_train.columns)

print("Initial Data Overview")
print(df_train.describe())
print(df_train.info())
print(df_train.head())

"""# 2. Feature Distribution Analysis Before Scaling

"""

plt.figure(figsize=(14, 12))
for i, col in enumerate(df_train.columns, 1):
    plt.subplot(4, 4, i)
    sns.histplot(df_train[col], kde=True, bins=30)
    plt.title(f'Distribution of {col}')
    plt.tight_layout()
plt.show()

"""# 3. Apply Feature Scaling

"""

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""# Create DataFrames for scaled data

"""

df_train_scaled = pd.DataFrame(X_train_scaled, columns=df_train.columns)
df_test_scaled = pd.DataFrame(X_test_scaled, columns=df_train.columns)

"""
# Plot feature distributions after scaling
"""

plt.figure(figsize=(14, 12))
for i, col in enumerate(df_train_scaled.columns, 1):
    plt.subplot(4, 4, i)
    sns.histplot(df_train_scaled[col], kde=True, bins=30)
    plt.title(f'Distribution of {col} (scaled)')
    plt.tight_layout()
plt.show()

"""# 4. Model Training and Evaluation with Different Kernels


"""

kernels = ['linear', 'poly', 'rbf', 'sigmoid']

for kernel in kernels:
    print(f'\nKernel: {kernel}')

    # Initialize the SVM model with the specified kernel
    svm_model = SVC(kernel=kernel, probability=True, random_state=42)

    # Train the model
    svm_model.fit(X_train_scaled, y_train)

    # Make predictions
    y_pred_svm = svm_model.predict(X_test_scaled)

    # Evaluate the model
    accuracy_svm = accuracy_score(y_test, y_pred_svm)
    conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)
    class_report_svm = classification_report(y_test, y_pred_svm)

    # Print the results
    print(f'Accuracy: {accuracy_svm:.2f}')
    print('Confusion Matrix:\n', conf_matrix_svm)
    print('Classification Report:\n', class_report_svm)

"""#Explanation of the EDA Steps
**Initial Data Exploration**  
Descriptive Statistics: Use describe() to get summary statistics for each feature, such as mean, standard deviation, and percentiles.
Info and Head: Use info() to get data types and non-null counts, and head() to view the first few rows of the dataset.
Feature Distribution Analysis Before Scaling:

**Histograms with KDE:** Visualize the distribution of each feature in the training set before scaling. This helps in understanding the original data's spread and range.
Feature Scaling:

**Scaling:** Apply StandardScaler to standardize the features, transforming them to have a mean of 0 and a standard deviation of 1.
Post-Scaling Histograms: Plot histograms of scaled features to verify that they are centered around 0 and have similar variance.
Model Training and Evaluation with Different Kernels:

**Training and Evaluation:** Iterate over different kernel types for the SVM model (linear, poly, rbf, sigmoid):
Train Model: Fit the SVM model with the current kernel.
Predict and Evaluate: Make predictions and evaluate performance using accuracy, confusion matrix, and classification report.
Print Results: Display the evaluation metrics for each kernel to compare their performance.
This comprehensive EDA script will help you understand the characteristics of your data, the effect of scaling, and the performance of different SVM kernels on the dataset.
"""